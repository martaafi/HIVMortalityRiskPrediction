# -*- coding: utf-8 -*-
"""streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IX43UZjVt0XYOMA2KhEjqd83LbkcFQ0w
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler
from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestCentroid
from sklearn.naive_bayes import GaussianNB
from imblearn.over_sampling import RandomOverSampler
import matplotlib.pyplot as plt
from lime.lime_tabular import LimeTabularExplainer
from sklearn.manifold import TSNE
from scipy.spatial import cKDTree
from matplotlib.colors import ListedColormap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
import plotly.express as px
import random
from matplotlib.colors import cnames
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.cluster import KMeans
from sklearn.impute import SimpleImputer
from sklearn.model_selection import StratifiedKFold
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.inspection import permutation_importance
from sklearn.model_selection import cross_val_predict, cross_validate, KFold
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.impute import SimpleImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report
from sklearn.svm import SVC
from sklearn.dummy import DummyClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.semi_supervised import LabelPropagation, LabelSpreading
from lightgbm import LGBMClassifier
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier, SGDClassifier, Perceptron
from sklearn.ensemble import (
    GradientBoostingClassifier,
    HistGradientBoostingClassifier,
    RandomForestClassifier,
    AdaBoostClassifier,
    BaggingClassifier,
    ExtraTreesClassifier,
    StackingClassifier
)
import streamlit.components.v1 as components

from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from sklearn.naive_bayes import BernoulliNB, GaussianNB
from sklearn.neighbors import KNeighborsClassifier, NearestCentroid
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.semi_supervised import LabelSpreading
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.metrics import (
    confusion_matrix, classification_report, roc_auc_score, roc_curve, ConfusionMatrixDisplay
)
from imblearn.over_sampling import RandomOverSampler

import sklearn
import streamlit as st


st.set_page_config(layout="wide")
st.write("Scikit-learn version:", sklearn.__version__)


st.title("ü©∫ Health Risk Classification Dashboard")

# 1. File Upload
uploaded = st.file_uploader("Upload your health dataset (XLSX)", type="xlsx")
if not uploaded:
    st.stop()
df0 = pd.read_excel(uploaded)
st.subheader("Data sample")
st.dataframe(df0.head())

# 2. Preprocessing
@st.cache_data
def preprocess(df0):
    df = df0.copy()
    cols = ['Age Group','Gender','Per Capita Income (USD)','Education Index',
            'Prevalence Rate (%)','Incidence Rate (%)','Healthcare Access (%)',
            'Doctors per 1000','Population Affected','Disease Category','DALYs',
            'Treatment Type','Availability of Vaccines/Treatment',
            'Recovery Rate (%)','Improvement in 5 Years (%)','Hospital Beds per 1000',
            'Mortality Rate (%)']
    df = df[cols].dropna()
    q3 = df['Mortality Rate (%)'].quantile(0.75)
    bins = [-float('inf'), q3, float('inf')]
    labels = [0, 1] #0: Low, 1: High
    df['Mortality Rate (%)'] = pd.cut(df['Mortality Rate (%)'], bins=bins, labels=labels, right=False)

    def bin_col(data, col):
        q1, q3 = data[col].quantile([.25, .75])
        bins = [-np.inf, q1, q3, np.inf]
        data[col + '_Category'] = pd.cut(data[col], bins=bins, labels=['Low','Med','High'], right=False)
        return data.drop(columns=[col])

    df['Burden_Score'] = df['DALYs'] * df['Incidence Rate (%)'] * df['Population Affected']
    df['Access_Need_Ratio'] = df['Healthcare Access (%)'] / (df['Prevalence Rate (%)'] + 1e-6)
    df['Severity_Score'] = (100 - df['Recovery Rate (%)']) + (100 - df['Healthcare Access (%)']) + df['Prevalence Rate (%)']


    cont = ['Per Capita Income (USD)','Education Index','Prevalence Rate (%)',
            'Incidence Rate (%)','Healthcare Access (%)','Doctors per 1000',
            'Population Affected','DALYs','Recovery Rate (%)',
            'Improvement in 5 Years (%)','Hospital Beds per 1000', 'Burden_Score',
            'Access_Need_Ratio', 'Severity_Score']
    for c in cont:
        df = bin_col(df, c)

    ohe_cols = ['Age Group', 'Gender', 'Disease Category', 'Treatment Type', 'Per Capita Income (USD)_Category','Education Index_Category','Prevalence Rate (%)_Category',
            'Incidence Rate (%)_Category','Healthcare Access (%)_Category','Doctors per 1000_Category',
            'Population Affected_Category','DALYs_Category','Recovery Rate (%)_Category', 'Burden_Score_Category', 'Access_Need_Ratio_Category',
            'Severity_Score_Category', 'Improvement in 5 Years (%)_Category','Hospital Beds per 1000_Category']

    cats = [col for col in ohe_cols]
    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    Xohe = ohe.fit_transform(df[cats])
    Xohe = pd.DataFrame(Xohe, columns=ohe.get_feature_names_out(cats), index=df.index)

    df = pd.concat([df.drop(columns=cats), Xohe], axis=1)
    df['Availability'] = LabelEncoder().fit_transform(df['Availability of Vaccines/Treatment'])
    df.drop(columns=['Availability of Vaccines/Treatment'], inplace=True)
    return df

df = preprocess(df0)
X = df.drop(columns=['Mortality Rate (%)'])
y = df['Mortality Rate (%)']
st.success("‚úÖ Preprocessing done")

# 3. Train/Test + Oversampling
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
ros = RandomOverSampler(random_state=0)
X_res, y_res = ros.fit_resample(X_train, y_train)

# 4. Model Selection UI
st.sidebar.subheader("Select 3 Classifiers")
choices = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "GradientBoosting": GradientBoostingClassifier(random_state=0),
    "HistGradientBoosting": HistGradientBoostingClassifier(random_state=0),
    "CatBoost": CatBoostClassifier(verbose=0, random_state=0),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=0),
    "LightGBM": LGBMClassifier(class_weight='balanced'),
    "GaussianNB": GaussianNB(),
    "SVC": SVC(probability=True),
    "MLPClassifier": MLPClassifier(),
    "KNeighbors": KNeighborsClassifier(),
    "NearestCentroid": NearestCentroid(),
    "DecisionTree": DecisionTreeClassifier(),
    "RandomForest": RandomForestClassifier(),
    "ExtraTrees": ExtraTreesClassifier(),
    "AdaBoost": AdaBoostClassifier(),
    "Bagging": BaggingClassifier(),
    "QDA": QuadraticDiscriminantAnalysis(),
}

selected = st.sidebar.multiselect("Models", list(choices.keys()))
if len(selected) != 3:
    st.sidebar.warning("Pick exactly 3 models for comparison")
    st.stop()

models = [choices[m] for m in selected]

# 5. ROC Curves
st.subheader("üìâ ROC Curves Comparison")
plt.figure(figsize=(6, 5))
results = []

for m in models:
    name = type(m).__name__
    m.fit(X_res, y_res)

    if hasattr(m, "predict_proba"):
        y_proba = m.predict_proba(X_test)[:, 1]
    elif hasattr(m, "decision_function"):
        y_proba = m.decision_function(X_test)
    else:
        st.warning(f"‚ö†Ô∏è Model '{name}' does not support ROC (no predict_proba or decision_function). Skipped.")
        continue

    fpr, tpr, _ = roc_curve(y_test, y_proba)
    auc = roc_auc_score(y_test, y_proba)
    recall = classification_report(y_test, m.predict(X_test), output_dict=True)['1']['recall']

    results.append({'Model': name, 'Recall': recall, 'AUC': auc})
    plt.plot(fpr, tpr, label=f"{name} (AUC={auc:.5f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.legend()
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
st.pyplot(plt.gcf())

roc_df = pd.DataFrame(results).set_index('Model').sort_values(['Recall', 'AUC'], ascending=False)
st.dataframe(roc_df.style.format({"Recall": "{:.5f}", "AUC": "{:.5f}"}))

# 6. Confusion Matrices
st.subheader("üß© Confusion Matrices")
n = len(models); cols = 3; rows = (n+2)//3
fig, axes = plt.subplots(rows, cols, figsize=(5*cols,4*rows))
axes = axes.flatten()
for i,m in enumerate(models):
    y_pred=m.predict(X_test)
    disp=ConfusionMatrixDisplay.from_predictions(y_test,y_pred, ax=axes[i], cmap="Blues", colorbar=False)
    axes[i].set_title(type(m).__name__)
    axes[i].grid(False)
for ax in axes[len(models):]:
    ax.axis('off')
st.pyplot(fig)

# 7. t-SNE Decision Boundary
st.subheader("üîç t‚ÄëSNE Decision Boundary (Recall annotated)")
for m in models:
    m.fit(X_res, y_res)
X_tsne = TSNE(n_components=2, random_state=42).fit_transform(X_test)

grid_h = 0.5
x_min, x_max = X_tsne[:, 0].min() - 1, X_tsne[:, 0].max() + 1
y_min, y_max = X_tsne[:, 1].min() - 1, X_tsne[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_h),
                     np.arange(y_min, y_max, grid_h))
tree = cKDTree(X_tsne)
_, idx = tree.query(np.c_[xx.ravel(), yy.ravel()])

colormaps = [
    ListedColormap(["#cc0000", "#0000cc"]),  # Dark Red & Dark Blue
    ListedColormap(["#990000", "#000099"]),  # Deeper Red & Navy
    ListedColormap(["#800000", "#000080"]),  # Maroon & Dark Blue

]

for i, m in enumerate(models):
    preds = m.predict(X_test.iloc[idx])
    Z = preds.reshape(xx.shape)
    recall = classification_report(y_test, m.predict(X_test), output_dict=True)['1']['recall']

    fig, ax = plt.subplots(figsize=(6, 5))
    ax.contourf(xx, yy, Z, alpha=0.3, cmap=colormaps[i])
    ax.scatter(*X_tsne[y_test == 0].T, c='red', label='Low risk', s=15, alpha=0.6)
    ax.scatter(*X_tsne[y_test == 1].T, c='blue', label='High risk', s=15, alpha=0.6)
    ax.set_title(f"{type(m).__name__} (Recall: {recall:.2f})")
    ax.set_xlabel("t‚ÄëSNE 1")
    ax.set_ylabel("t‚ÄëSNE 2")
    ax.legend()
    st.pyplot(fig)

# 8. LIME Explanation
st.subheader("üß† LIME Explanation (first test sample)")
explainer = LimeTabularExplainer(
    training_data=X_res.values,
    feature_names=X_res.columns.tolist(),
    class_names=['Low Mortality Risk','High Mortality Risk'],
    mode='classification'
)
exp = explainer.explain_instance(
    data_row=X_test.iloc[0].values,
    predict_fn=models[0].predict_proba
)
html = exp.as_html()
components.html(html, height=600)

# 9. Interactive Risk Visualizations
st.subheader("üìä Interactive Visualization by Demographics")
df_viz = df0.copy().reset_index(drop=True)
df_viz['Predicted Risk'] = models[0].predict_proba(X)[:, 1]

st.markdown("#### üî¥ Average Mortality Risk by Age Group")
age_risk = df_viz.groupby('Age Group')['Predicted Risk'].mean().reset_index()
fig1, ax1 = plt.subplots(figsize=(10, 6))
sns.barplot(data=age_risk, x='Age Group', y='Predicted Risk', palette='Reds', ax=ax1)
ax1.set_title('Predicted Health Risk by Age Group')
ax1.set_ylabel('Average Predicted Risk')
ax1.set_xlabel('Age Group')
ax1.set_ylim(0, 1)
st.pyplot(fig1)

st.markdown("#### üî• Risk Heatmap by Gender and Age Group")
heat_data = df_viz.groupby(['Age Group', 'Gender'])['Predicted Risk'].mean().unstack()
fig2, ax2 = plt.subplots(figsize=(8, 6))
sns.heatmap(heat_data, annot=True, cmap='Reds', fmt=".2f", ax=ax2)
ax2.set_title('Predicted Health Risk by Age Group and Gender')
ax2.set_ylabel('Age Group')
ax2.set_xlabel('Gender')
st.pyplot(fig2)

st.markdown("#### üì¶ Risk Distribution by Disease Category")
fig3, ax3 = plt.subplots(figsize=(12, 6))
sns.boxplot(data=df_viz, x='Disease Category', y='Predicted Risk', palette='Reds', ax=ax3)
ax3.set_title('Distribution of Predicted Risk by Disease Category')
ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45, ha='right')
st.pyplot(fig3)

st.markdown("#### üî• Heatmap of Average Risk by Disease Category and Treatment Availability")
heat_avail = df_viz.groupby(['Disease Category', 'Availability of Vaccines/Treatment'])['Predicted Risk'].mean().unstack()
fig5, ax5 = plt.subplots(figsize=(10, 6))
sns.heatmap(heat_avail, annot=True, cmap='Reds', fmt=".2f", ax=ax5)
ax5.set_title("Average Predicted Risk per Disease Category vs Treatment Availability")
st.pyplot(fig5)

st.markdown("#### ‚è≥ Predicted Risk Over Time")
if 'Year' in df_viz.columns:
    fig10, ax10 = plt.subplots(figsize=(10, 6))
    sns.lineplot(data=df_viz, x='Year', y='Predicted Risk', hue='Disease Name', estimator='mean', ax=ax10)
    ax10.set_title('Average Predicted Risk Over Time')
    st.pyplot(fig10)

st.balloons()